import os
from typing import List
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
from agents.langchain_agent import VulnAgent
from prompts.prompts import SYSTEM_PROMPT_MULTI, SYSTEM_PROMPT_FROM_SEARCH
from schemas.pydantic_schemas import VulnerabilityList, Vulnerability
from tools.websearch import search_results_for_vuln
from langchain.output_parsers import PydanticOutputParser
from langchain_openai.chat_models import ChatOpenAI
from dotenv import load_dotenv
from pathlib import Path

# Load environment variables
load_dotenv(dotenv_path=Path(__file__).resolve().parent.parent.parent / ".env")

def get_env_var(name: str, default: str = None, required: bool = False):
    value = os.getenv(name, default)
    if required and value is None:
        raise ValueError(f"Missing required environment variable: {name}")
    return value

# Config
API_KEY = get_env_var("API_KEY", required=True)
MODEL = get_env_var("MODEL", required=True)
BASE_URL = get_env_var("BASE_URL", required=True)
TEMPERATURE = float(get_env_var("TEMPERATURE", default="0.6"))

# FastAPI app
app = FastAPI(title="Vulnerability Analyzer")

class VulnerabilityInput(BaseModel):
    vulnerabilities: List[str]

# Original Agent for LLM-based vuln extraction
agent = VulnAgent(
    api_key=API_KEY,
    model=MODEL,
    system_prompt=SYSTEM_PROMPT_MULTI,
    pydantic_class=VulnerabilityList,
    base_url=BASE_URL,
    temperature=TEMPERATURE
)

@app.post("/vulns_details")
async def vulns_details(data: VulnerabilityInput):
    try:
        structured_data, _ = agent.get_vulns_details(data.vulnerabilities)

        final_results = []
        for i, vuln_input in enumerate(data.vulnerabilities):
            try:
                vuln_info = structured_data.vulnerabilities[i]
                analysis = {
                    "description": vuln_info.description,
                    "remediation": vuln_info.remediation,
                    "severity": vuln_info.severity,
                    "category": vuln_info.category,
                    
                }

                search_query = f"{vuln_input} vulnerability exploit remediation"
                search_results = search_results_for_vuln(search_query)

                final_results.append({
                    "vulnerability": vuln_input,
                    "analysis": analysis,
                    "search_results": search_results
                })

            except IndexError:
                continue

        return {"results": final_results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing vulnerabilities: {str(e)}")

@app.post("/vulns_from_search")
async def vulns_from_search(data: VulnerabilityInput):
    try:
        final_results = []

        for vuln_input in data.vulnerabilities:
            # Extract possible keywords from the vulnerability identifier
            keywords = []
            vuln_type = None
            url = None
            
            # Extract key components from the vulnerability string
            if '[' in vuln_input and ']' in vuln_input:
                identifier = vuln_input.split(']')[0].strip('[')
                keywords = [part for part in identifier.split('-') if len(part) > 2]
                
                # Try to extract the URL from the vulnerability input
                import re
                url_match = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', vuln_input)
                if url_match:
                    url = url_match.group(0)
            
            # Create a more specific search query based on the vulnerability identifier
            search_query = vuln_input
            if keywords:
                # Construct a more targeted search query using the extracted keywords
                search_query = " ".join(keywords) + " vulnerability"
                if url:
                    # Add the endpoint or path to the search query for more specificity
                    path_parts = url.split('/')
                    if len(path_parts) > 3:
                        endpoint = '/'.join(path_parts[3:])
                        search_query += f" {endpoint}"
            
            search_results = search_results_for_vuln(search_query)
            if not search_results:
                final_results.append({"error": "No search results found for: " + vuln_input})
                continue

            # Use the first search result's snippet and link if available
            link = search_results[0].get("link") if search_results else None
            snippet = search_results[0].get("snippet") if search_results else None

            search_context = f"Snippet: {snippet}\nLink: {link}" if snippet or link else ""
            
            # Include vulnerability information in the prompt
            additional_context = f"Vulnerability identifier: {vuln_input}"
            if keywords:
                additional_context += f"\nKeywords from identifier: {', '.join(keywords)}"
            if url:
                additional_context += f"\nTarget URL: {url}"

            prompt = SYSTEM_PROMPT_FROM_SEARCH + f"\n\nVulnerability context:\n{additional_context}\n\nSearch context:\n{search_context}\n\nRespond with structured JSON only."

            llm = ChatOpenAI(model=MODEL, base_url=BASE_URL, api_key=API_KEY, temperature=TEMPERATURE)
            parser = PydanticOutputParser(pydantic_object=Vulnerability)
            schema_hint = parser.get_format_instructions()
            full_prompt = f"{prompt}\n\nSchema format:\n{schema_hint}\n\nOutput (as JSON):```json"

            response = llm.invoke(full_prompt)
            
            # Process LLM response with error handling
            try:
                # First extract the raw response content
                response_content = str(response.content)
                
                # Try to manually extract and parse JSON from the content if needed
                import json
                import re
                
                # Check if content has JSON code blocks
                json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response_content, re.DOTALL)
                if json_match:
                    # Extract JSON from code block
                    json_content = json_match.group(1)
                    try:
                        # Try parsing the extracted JSON
                        result_dict = json.loads(json_content)
                        
                        # Truncate fields if needed to match schema requirements
                        if "description" in result_dict and len(result_dict["description"]) > 1000:
                            result_dict["description"] = result_dict["description"][:997] + "..."
                            
                        if "remediation" in result_dict and len(result_dict["remediation"]) > 2000:
                            result_dict["remediation"] = result_dict["remediation"][:1997] + "..."
                            
                        # Create a valid response for the parser
                        response_content = json.dumps(result_dict)
                    except json.JSONDecodeError:
                        # If parsing fails, proceed with original content
                        pass
                
                # Use the Pydantic parser with the processed content
                parsed = parser.parse(response_content)
                analysis = parsed.model_dump()
            except Exception as e:
                print(f"Error parsing LLM response: {str(e)}")
                # Create a default analysis on error
                analysis = {
                    "description": "Error parsing LLM response: " + str(e)[:200],
                    "remediation": "The system encountered an error while processing this vulnerability.",
                    "category": "Unknown",
                    "severity": "unknown"
                }
            
            # Store search query for internal use but don't include in response
            search_query_used = search_query
            
            # Move snippet and link to top-level
            if link:
                analysis["link"] = link
            if snippet:
                analysis["snippet"] = snippet

            final_results.append(analysis)

        return {"results": final_results}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=6666)
